{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgEBkW996mCoxaH1ZBGvda",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishwanaik15/DM-ASSIGNMENT03/blob/main/Assignment_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJwfOIChVhHX"
      },
      "source": [
        "Name: Vishwa Chetankumar Naik</br>\n",
        "UTA ID:1001871311</br>\n",
        "Assignment - 03 </br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8Np3u_nVo__"
      },
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR7vmGNtOarK"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import Series\n",
        "import re\n",
        "from sys import path\n",
        "from collections import Counter\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "%matplotlib inline\n",
        "import re\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8qGzDUmVqkT"
      },
      "source": [
        "**A)Divide the dataset as train and development.**</br>\n",
        "--Here I have used dataset from kaggle sentiment labelled sentences dataset.</br>\n",
        "--I have imported test data at the last of  assignment because in the last question it is required, so just to remove confusion.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYeQWyY8OeAH",
        "outputId": "9e5d3e78-b686-43b3-9741-347f12cafa56"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYJwUJg-OgDY",
        "outputId": "156238eb-26ca-4bb8-a355-d36ea5738736"
      },
      "source": [
        "imdb_data = pd.read_csv('/content/gdrive/My Drive/data/imdb_labelled.txt', delimiter='\\t', header=None, names=['review', 'sentiment'])\n",
        "print(imdb_data.shape)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(748, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoMEOGpKVzzQ"
      },
      "source": [
        "#dataset understanding and preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "kng4MNCcOnzq",
        "outputId": "68aecb85-353d-4e08-dac8-614c4c588aac"
      },
      "source": [
        "imdb_data.head()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not sure who was more lost - the flat characte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very little music or anything to speak of.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  A very, very, very slow-moving, aimless movie ...          0\n",
              "1  Not sure who was more lost - the flat characte...          0\n",
              "2  Attempting artiness with black & white and cle...          0\n",
              "3       Very little music or anything to speak of.            0\n",
              "4  The best scene in the movie was when Gerardo i...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyKhRUFZOp3d",
        "outputId": "785a0def-6759-4923-92e7-276c01854439"
      },
      "source": [
        "imdb_data.info()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 748 entries, 0 to 747\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     748 non-null    object\n",
            " 1   sentiment  748 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 11.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkildQYyOtgd",
        "outputId": "c036dc3a-98dc-45f8-eabe-0da52657cc0b"
      },
      "source": [
        "imdb_data.isnull().sum()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review       0\n",
              "sentiment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hadIllr1OwxK",
        "outputId": "cb21b625-bb0e-4f1b-d33d-b9048a0f5b42"
      },
      "source": [
        "imdb_data.sentiment.value_counts()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    386\n",
              "0    362\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0-QONuTOyhy",
        "outputId": "eb770c15-1dce-4a6e-a9ad-95a5d2664c72"
      },
      "source": [
        "shuffle = imdb_data.sample(frac=1).to_numpy()\n",
        "#shuffling data using sample method to get random values in train and development set each time \n",
        "size = int(0.65*len(imdb_data))\n",
        "#i have taken 65% of data as training and rest of 40% data as development set \n",
        "train_set = shuffle[:size]\n",
        "development_set = shuffle[size:]\n",
        "print(\"Size of training set: \",len(train_set))\n",
        "print(\"Shape of training set:\",{train_set.shape})\n",
        "print(\"Size of develpment set: \",len(development_set))\n",
        "print(\"Shape of development set:\",{development_set.shape})\n"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training set:  486\n",
            "Shape of training set: {(486, 2)}\n",
            "Size of develpment set:  262\n",
            "Shape of development set: {(262, 2)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa-SMIUfO6gT"
      },
      "source": [
        "X_train = train_set[:,0] #reviews in X_train\n",
        "Y_train = train_set[:,-1] #last column goes in Y_train which shows labels 0 or 1\n",
        "X_development = development_set[:,0]\n",
        "Y_development = development_set[:,-1]"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhnHgXgQWEbs"
      },
      "source": [
        "**b>Build a vocabulary as list. **</br>\n",
        "[‘the’ ‘I’ ‘happy’ … ] </br>\n",
        "You may omit rare words for example if the occurrence is less than five times\n",
        "A reverse index as the key value might be handy</br>\n",
        "{“the”: 0, “I”:1, “happy”:2 , … }\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3BwFQbHO-pj"
      },
      "source": [
        "#vocabulary list\n",
        "a = {}\n",
        "vocab_list=[]\n",
        "def build_vocab_list(imdb_data):\n",
        "    a = counting_number_of_unique_words(imdb_data)\n",
        "    for i in a.keys():\n",
        "        vocab_list.append(i)\n",
        "    return vocab_list"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF0vJFbSPB1a"
      },
      "source": [
        "#counting unique number of words in dataset so we can compare after removing less occurring words \n",
        "words_count = {}\n",
        "def counting_number_of_unique_words(imdb_data):\n",
        "    for line in imdb_data:\n",
        "        for word in line.split():\n",
        "            if word in words_count:\n",
        "                words_count[word] = words_count[word] + 1\n",
        "            else:\n",
        "                words_count[word] = 1\n",
        "    return words_count\n"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4tig_dxPIMP",
        "outputId": "31cad054-7b27-4850-b8da-2e4439945e0c"
      },
      "source": [
        "#before removing less occurring data \n",
        "words_count = counting_number_of_unique_words(X_train)\n",
        "print(\"Total unique words in the given dataset before removing less occurring words: \",len(words_count))\n"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unique words in the given dataset before removing less occurring words:  2756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNYq5AfQPKRj",
        "outputId": "2ee0a08b-2194-40cf-bb38-7ef2213254b2"
      },
      "source": [
        "print(words_count) #with less occurring words/\n"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'However': 1, 'Paul': 3, 'Schrader': 1, 'has': 25, 'indeed': 1, 'made': 12, 'a': 233, 'film': 58, '\"about\"': 1, 'Mishima': 1, 'that': 87, 'is': 182, 'both': 7, 'superb': 2, '&': 7, 'complex.': 1, 'The': 107, 'rest': 3, 'of': 199, 'the': 366, 'movie': 70, 'lacks': 4, 'art,': 2, 'charm,': 1, 'meaning...': 1, 'If': 7, \"it's\": 17, 'about': 25, 'emptiness,': 1, 'it': 84, 'works': 3, 'I': 142, 'guess': 3, 'because': 12, 'empty.': 1, 'All': 6, 'actors': 7, 'give': 5, 'wonderful': 9, 'performance,': 1, 'especially': 4, 'Jennifer': 1, 'Rubin': 1, 'as': 52, 'Jamie': 1, 'Harris,': 1, 'who': 23, 'changes': 1, 'from': 24, 'nervous': 1, 'starlet': 1, 'in': 116, 'beginning': 3, 'through': 5, 'strange': 1, 'events': 1, 'she': 5, 'part': 6, 'to': 128, 'cool': 4, 'star.': 1, 'But': 8, 'if': 16, 'you': 31, 'liked': 6, 'movies': 12, 'like': 25, 'Matrix': 1, '(and': 3, 'better': 8, 'yet,': 1, 'their': 10, 'sequels)': 1, 'think': 5, \"you'll\": 1, 'appreciate': 4, 'thought': 6, 'provoking,': 1, 'mindblowing': 1, 'experience': 2, 'this': 106, 'will': 14, 'you.': 1, 'Go': 2, 'watch': 6, 'it!': 3, 'This': 44, 'now': 3, 'joins': 1, 'Revenge': 1, 'Boogeyman': 1, 'and': 235, 'Zombiez': 1, 'hellish': 1, 'trinity': 1, 'horror': 1, 'films.': 2, 'interplay': 2, 'between': 7, 'Martin': 2, 'Emilio': 2, 'contains': 1, 'same': 4, 'chemistry': 3, 'we': 6, 'saw': 7, 'Wall': 1, 'Street': 1, 'with': 50, 'Charlie.': 1, 'Considering': 1, 'relations': 2, 'off': 5, 'screen': 2, 'Taylor': 1, 'Stanwyck,': 1, 'was': 104, 'surprising': 2, 'how': 15, 'little': 12, 'there': 14, 'on': 35, 'two': 12, 'them.': 3, 'Not': 5, 'recommended.': 2, 'As': 3, 'for': 52, 'killer,': 2, \"don't\": 10, 'expect': 4, 'anything': 5, 'original': 1, 'or': 25, 'even': 17, 'remotely': 2, 'frightening.': 2, 'Cinematography': 1, 'noteworthy': 1, 'including': 2, 'fine': 3, 'views': 1, 'Barcelona': 1, 'its': 16, 'famed': 1, 'Gaudi': 1, 'towers.': 1, 'success': 1, 'depends': 1, 'casting': 3, 'Sydney': 1, 'Greenstreet': 1, 'Alexander': 1, 'Yardley': 1, 'character.': 2, 'hate': 2, 'that.': 1, 'visual': 3, 'effects': 4, 'were': 17, 'AWFUL.': 1, 'just': 35, 'recommend': 8, 'it.': 20, 'one': 26, 'fails': 3, 'create': 1, 'any': 15, 'real': 8, 'suspense.': 2, 'There': 6, 'NO': 2, 'Ben': 1, 'Affleck': 1, 'Sandra': 1, 'Bullock': 1, 'film,': 6, \"couldn't\": 3, 'understand': 6, 'why': 3, 'he': 18, 'would': 8, 'consider': 3, 'leaving': 1, 'his': 21, 'wife-to-be': 1, 'chick': 2, 'supposedly': 2, 'knocked': 1, 'out': 19, 'by.': 1, 'really': 25, 'loved': 5, 'story': 13, 'line': 5, 'poler': 1, 'bear': 2, 'kinda': 2, 'cute.But': 1, 'anyone': 7, 'question': 2, 'Fort': 1, 'Steele,': 1, 'ask': 1, 'away:)': 1, '\"Mirrormask\"': 1, 'last': 4, 'night': 2, 'an': 26, 'unsatisfactory': 1, 'experience.': 1, 'got': 4, 'bored': 3, 'watching': 11, 'Jessice': 1, 'Lange': 2, 'take': 4, 'her': 11, 'clothes': 1, 'off!': 1, 'It': 29, 'failed': 1, 'convey': 1, 'broad': 1, 'sweep': 1, 'landscapes': 1, 'great': 19, 'original.': 2, 'He': 4, \"didn't\": 7, 'seem': 2, 'want': 3, 'be': 22, 'hosting;': 1, 'voice-overs': 1, 'monotonous,': 1, 'get': 8, 'involved': 3, 'guests.': 1, 'sets': 3, 'are': 42, 'so': 27, 'bad,': 4, 'they': 12, \"wouldn't\": 1, 'look': 8, 'place': 3, 'Thunderbirds': 1, 'episode.': 1, 'true': 3, 'classic.': 2, 'things': 5, 'four': 1, 'kids': 3, 'themselves': 2, 'into': 11, 'absolutely': 6, 'hilarious': 3, 'watch.': 5, 'See': 3, 'films': 9, 'can.': 1, 'Perabo': 1, 'nice': 4, 'energy': 1, 'level': 1, 'obviously': 1, 'very': 25, 'comfortable': 1, 'front': 1, 'camera.': 1, 'almost': 4, 'no': 16, 'action': 3, 'scenes': 9, 'comedy.': 1, '15': 1, 'minutes': 5, 'also': 13, 'not': 35, 'bad': 26, 'well.': 6, 'Julian': 1, 'Fellowes': 1, 'triumphed': 1, 'again.': 3, 'plot,': 2, 'such': 8, 'is,': 5, 'derivative': 1, 'predictable': 3, 'ending': 5, 'mercy': 2, 'killing.': 1, 'showed': 1, 'exactly': 3, 'government': 1, 'scientist': 1, 'argued': 1, 'humanity': 1, 'reasons': 1, '\"gadget\".': 1, 'features': 1, 'outlandish': 1, 'array': 1, 'memorable,': 1, 'psychotic': 1, 'but': 38, 'lovable': 1, 'nuts.': 1, 'good': 23, 'cinematography': 4, 'makes': 6, 'Monica': 1, 'Bellucci': 1, 'beautiful.': 2, 'may': 4, 'only': 14, 'ever': 15, 'made.': 2, 'CG': 1, 'opening': 2, 'sequence': 2, 'space': 2, 'looked': 3, 'could': 11, 'have': 24, 'been': 9, 'created': 2, 'Microsoft': 1, 'Slideshow': 1, \"God's\": 1, 'sake!': 1, 'cant': 1, 'explain': 2, 'more': 24, 'than': 12, 'romantic,charming,hilarious,and': 1, 'adorable.The': 1, 'junkyard': 2, 'funny,all': 1, 'dogs': 1, 'something': 2, 'special.Too': 1, 'funny': 6, 'i': 7, 'laughed,kids': 1, 'LOVE': 1, 'it.Buy': 1, 'when': 18, 'comes': 3, 'out,it': 1, 'new': 2, 'features!': 1, 'Every': 3, 'time': 14, 'opened': 1, 'mouth': 1, 'hear,': 1, '\"you': 1, 'see': 10, 'kids...\"': 1, 'Pulling': 1, 'plug': 1, 'killing': 1, 'horrible': 2, 'show.': 1, 'holds': 1, 'your': 11, 'complete': 2, 'attention,': 1, 'acting': 22, 'superb,': 2, 'Tom': 1, 'Wilkinson': 1, 'fantastic': 1, 'Emily': 1, 'Watson': 1, 'good.': 3, 'particularly': 4, 'pleased': 1, 'ability': 3, 'Dwight': 1, 'Schultz.': 1, 'With': 2, 'sound': 3, 'effects,': 4, 'impressive': 2, 'special': 7, \"can't\": 7, 'enough.': 1, '1': 17, 'Call': 1, 'me': 8, 'nut,': 1, 'best': 11, 'ever.': 1, 'Great': 2, 'character': 9, 'Telly': 1, 'Savalas': 1, 'Peter': 1, 'Boyle.': 1, 'hour': 2, '54': 1, 'sheer': 1, 'tedium,': 1, 'melodrama': 1, 'acting,': 6, 'mess': 3, 'script,': 2, 'sinking': 1, 'feeling': 4, 'GOOD': 1, 'LORD,': 1, 'WHAT': 1, 'WERE': 1, 'THEY': 1, 'THINKING?': 1, '0': 38, 'Lots': 1, 'holes': 3, 'script.': 4, \"It's\": 19, 'TV': 2, 'movie.': 15, 'Now': 3, 'imagine': 1, 'every': 8, 'single': 3, 'those': 6, 'decisions': 1, 'wrong.': 2, 'dialogue': 5, 'atrocious.': 1, 'beyond': 3, 'abysmal.': 1, 'Everything': 5, 'stinks.': 1, 'Trouble': 1, 'writing': 6, 'directing': 6, 'make': 13, 'impossible': 1, 'establish': 1, 'watchable,': 1, 'character,': 2, 'story,': 2, 'theme': 1, 'on.': 3, 'Worse,': 1, \"there's\": 4, 'incredibly': 2, 'weak': 2, 'sub-plot': 1, 'thrown': 2, 'follows': 1, 'band': 1, 'latter-day': 1, 'Mansonites': 1, 'go': 5, 'after': 9, 'reporter': 1, \"who's\": 1, 'working': 1, 'anniversary': 1, 'killings.': 1, 'dumb': 2, 'pointless,': 1, 'waste': 6, 'time.': 9, 'In': 5, 'short,': 1, 'bother': 2, \"won't\": 4, 'spoil': 2, 'it,': 6, 'pretty': 6, 'amazing.': 2, 'scene': 8, 'at': 33, 'end,': 1, 'indication': 1, 'writer': 2, \"director's\": 1, 'meld': 1, 'highly': 4, 'volatile': 1, 'temperaments': 1, 'seamless': 1, 'union': 1, 'creativity,': 1, 'then': 1, 'result': 2, 'powerhouse': 1, 'achievement,': 1, 'timely': 1, 'perhaps': 2, 'our': 3, \"culture's\": 1, 'disturbing': 1, 'fascination': 1, 'celebrity,': 1, 'distorted': 1, 'interpretations': 1, 'fame.': 1, 'A': 7, 'easily': 1, 'forgotten.': 1, 'But,': 1, 'Kevin': 1, 'Spacey': 1, 'excellent,': 1, 'verbal': 1, 'tsunami': 1, 'Buddy': 1, 'Ackerman': 1, '\\x96': 4, 'totally': 9, 'believable': 4, 'actor.': 2, 'scripting': 1, 'subtle': 5, 'comedy': 2, 'unmatched': 1, 'by': 28, 'recent': 2, 'years.': 5, 'characters': 19, 'interesting,': 3, 'bit': 3, 'predictable.': 3, 'Highly': 3, 'recommended': 3, 'all': 27, 'ages,': 1, 'although': 2, 'younger': 1, 'set': 3, 'probably': 5, 'some': 12, 'references,': 1, 'certainly': 4, 'galley': 1, 'particular!': 1, 'movie!': 2, 'Also': 4, 'weak.': 1, 'At': 4, 'around': 3, '4': 2, 'pm': 1, 'bought': 2, '8pm': 1, 'started': 2, 'watch,': 2, '8.15pm': 1, 'fast': 4, 'forwarded': 1, 'remaining': 1, 'left': 3, 'watchable': 1, 'human': 4, 'being': 7, 'brain...': 1, \"wasn't.\": 1, 'Either': 1, 'way,': 1, 'sucks.': 3, 'script': 10, 'horrendously': 1, 'stupid.': 3, 'starts': 2, 'too': 5, 'suspense': 2, 'build-up': 1, 'slightest.': 1, 'Captain': 1, 'Howdy': 1, 'says': 1, 'either': 1, 'laughable': 1, 'plain': 2, 'What': 5, 'hell': 2, 'kind': 5, 'crap': 1, 'that?!': 1, 'Then,': 1, 'plot': 13, 'holes.': 1, 'You': 6, 'drive': 1, 'semi': 1, 'truck': 1, 'these': 4, 'holes!': 1, 'Linda': 1, 'Cardellini': 1, 'thing': 1, 'film.': 11, \"She's\": 1, 'poised': 1, 'Dee': 1, 'Snider': 1, 'act': 1, '(one': 2, 'least': 3, 'scary': 1, 'villains': 1, 'seen),': 1, 'write': 3, '(did': 1, 'damn': 2, 'sleep?': 1, 'throughout': 6, 'whole': 3, 'thing.': 2, 'sucks,': 4, 'music': 8, 'pacing': 1, 'FX': 1, 'suck,': 1, 'sucks...': 1, 'basically,': 1, 'tries': 1, 'serious': 2, 'sophisticated': 1, 'thriller/horror': 1, 'flick': 2, 'miserably.': 1, 'effective': 2, 'utterly': 2, 'unoriginal': 1, 'seen': 6, 'my': 12, 'entire': 4, 'life.': 3, 'piece': 4, 'cinematic': 1, 'garbage': 3, 'captured': 1, 'celluloid.': 1, 'Avoid': 3, 'costs.': 3, 'rate': 3, 'stinks,': 1, 'funny,': 2, 'Fulci': 1, 'should': 5, 'stayed': 1, 'giallo': 2, 'supernatural': 1, 'zombie': 1, 'movies.': 1, 'know': 11, 'what': 11, 'happened': 1, 'Season': 1, 'Five,': 1, 'mess.': 2, 'consistent': 1, 'thread': 1, 'holding': 1, 'series': 2, 'together': 2, 'amazing': 3, 'performances': 2, 'Leni': 1, 'Parker': 1, 'Anita': 1, 'LaSelva': 1, 'Taelons': 1, 'quiet': 1, 'idealogical': 1, 'conflict.': 2, 'dislike.': 1, 'most': 11, 'boring': 4, 'Horror': 1, \"90's\": 3, 'mainly': 1, 'slow': 2, 'centers': 1, 'atmosphere.': 1, 'puppets': 1, 'cheesy': 1, ',': 1, 'way': 6, 'Puppet': 1, 'Master': 1, \"80's\": 1, 'flicks.': 1, 'lame,': 1, 'interesting': 6, 'NEVER': 1, 'explains': 1, 'sinister': 1, 'origins': 1, 'puppets.': 1, \"aren't\": 2, 'death': 3, 'previous': 2, 'f/x': 1, 'terrible.': 1, 'felt': 4, 'asleep': 1, 'first': 4, 'watched': 5, 'can': 9, 'insomniacs.': 1, 'fact': 3, 'wonderful,': 2, 'heartwarming': 1, 'tale': 3, 'people': 7, 'chasing': 1, 'dreams.': 1, 'Nurse': 1, 'Betty\"': 1, 'unpredictability.': 1, 'Excellently': 1, 'produced': 1, \"Sci-fi's\": 1, 'producers': 1, 'Scot': 1, 'Vandiver': 1, '!': 1, 'That': 2, 'bad.': 7, 'cast': 7, 'great.': 1, 'need': 1, 'whenever': 1, 'TV...never': 1, 'mind': 2, 'already': 1, 'memorized!': 1, '9/10.': 1, 'soundtrack': 2, \"wasn't\": 1, 'terrible,': 3, 'either.': 1, 'Wasted': 1, 'hours.': 1, 'convention': 1, 'never': 4, 'worked': 1, 'well': 13, 'past,': 1, \"doesn't\": 10, 'work': 5, 'here.': 1, 'sad': 1, 'movie,': 7, 'guy': 1, 'said': 1, \"he's\": 1, 'had': 15, 'potted': 1, 'plants': 1, 'right.': 4, 'Jim': 1, \"O'Connor\": 1, 'energetic': 1, 'nobody': 2, 'much': 5, 'him,': 1, 'George': 1, 'dull.': 1, 'keep': 3, 'over': 9, 'over.': 1, 'Meredith': 1, 'M': 1, 'stories': 1, 'unbelievable': 2, 'actors.': 1, 'above': 1, 'exquisite': 2, 'composition': 2, 'each': 5, 'moment,': 1, 'inventive': 1, 'elegant': 1, 'use': 4, 'close-up,': 1, 'camera': 4, 'angle': 1, 'lighting,': 1, 'pointillistic': 1, 'faux': 2, 'home': 1, 'footage,': 1, 'wonder': 1, 'joy': 5, 'behold.': 1, 'Italian': 1, 'thrillers': 1, 'early': 2, \"70's.\": 1, 'Helen': 1, 'Baxendale': 1, 'credible': 1, 'lady': 1, 'Macbeth': 2, 'cheerfull': 1, 'times': 2, 'sometimes': 2, 'looks': 2, 'naughty': 1, 'girl,': 2, 'deadly': 1, 'taste': 1, 'blood': 1, 'evil.': 1, \"you'd\": 1, 'cast,': 2, 'top': 4, 'notch.': 1, ':)': 1, 'Anyway,': 1, 'flowed': 1, 'smoothly': 1, 'male-bonding': 1, 'hoot.': 1, 'acting--even': 1, 'professionals': 1, 'Drago': 3, 'Debbie': 1, 'Rochon--was': 1, 'worse': 3, '(perhaps': 1, 'contributory': 1, 'former),': 1, 'dialog': 2, 'chimp-like,': 1, 'work,': 1, 'barely': 3, 'tolerable.': 1, 'Again,': 1, 'all.': 3, 'Still,': 2, 'SETS': 1, 'big': 5, '\"10\"': 1, '\"oy-vey\"': 1, 'scale.': 2, 'fleshed': 1, 'surprisingly': 2, 'well,': 3, 'Grimes': 1, 'Blake,': 1, 'deliver': 1, 'sharply': 1, 'scripted': 1, 'lines': 1, 'right': 4, 'amount': 1, 'deadpan': 1, 'tongue': 1, 'cheek': 1, 'realistic.': 1, 'awful!': 1, 'photography.': 1, 'Easily,': 1, 'none': 1, 'other': 8, 'cartoon': 2, 'laugh': 1, 'tender': 1, '(before': 1, 'getting': 1, 'dark': 2, 'sitcoms': 1, 'oriented': 1, 'teenagers).': 1, 'knew': 2, 'come': 2, 'gifted': 1, 'Fans': 1, 'genre': 1, 'heaven.': 1, 'And': 6, 'accents': 1, 'abysmal!': 1, 'worst': 3, 'seen.': 4, 'Think': 1, 'dream.': 1, 'secondary': 1, 'incomprehensible': 1, 'relation': 1, 'primary': 1, 'mystifying.': 1, 'director.': 1, 'gripping,': 1, 'intelligent': 2, 'stage': 1, 'play': 4, '(but': 1, 'without': 2, 'overly': 2, 'theatrical': 1, 'actually': 6, 'gets': 4, 'stage)': 1, 'which': 10, 'plays': 2, \"everyone's\": 1, 'terror': 1, 'white': 6, 'lie': 1, 'escalating': 1, 'monstrous': 1, 'consequences.': 1, 'network': 1, 'aired': 1, 'dribble': 1, 'before': 2, 'putting': 1, 'always': 3, 'known': 1, 'Errol': 1, 'Flynn': 1, 'brilliant': 4, 'actor': 3, 'dads': 1, 'favourite': 1, 'actor,': 1, 'grew': 1, 'up': 9, 'child.': 1, 'reflected': 1, 'below-par': 1, 'borrowed': 1, 'earlier': 1, 'Songs': 1, 'Were': 2, 'Best': 2, 'Muppets': 1, 'So': 4, 'Hilarious.': 1, \"I'll\": 3, 'put': 3, 'gem': 2, 'against': 1, 'terms': 1, 'screenplay,': 1, 'cinematography,': 1, 'post-production,': 1, 'editing,': 1, 'directing,': 1, 'aspect': 2, 'film-making.': 1, 'still': 6, 'wild': 1, 'stuff': 1, 'though': 5, 'fans': 1, 'cinema.': 2, 'However,': 4, 'here': 4, 'decent': 3, 'location': 1, 'balance': 2, 'up.': 2, 'scary.': 1, 'People': 1, 'European': 1, '\"art': 1, 'movies\"': 1, 'Vivian': 1, 'Schilling': 1, 'did': 6, 'excellent': 6, 'job': 3, \"haven't\": 1, 'choked': 1, 'own': 3, 'vomit': 1, 'end': 5, '(by': 1, 'cheap': 3, 'drama': 2, 'worthless': 1, 'dialogue)': 1, \"you've\": 1, 'must': 3, 'yourself': 1, 'Cinematography:': 1, 'shot': 2, 'way.': 6, 'main': 3, 'players': 1, 'mesmerising.': 1, 'example': 3, 'established': 1, 'turn': 1, 'zombie-students': 1, 'back': 2, 'humans': 1, 'removing': 1, 'necklace': 1, 'containing': 1, 'meteorite.': 1, 'movie-making.': 1, 'Whatever': 2, 'producer': 1, 'going': 2, 'for,': 1, 'missed': 1, 'entirely.': 1, 'seems': 3, 'animation': 2, 'dominated': 1, \"Disney/Pixar's\": 1, 'CGI': 1, 'masterpieces,': 1, 'refreshing': 1, 'comforting': 1, 'Miyazaki': 1, 'relying': 1, 'traditional': 1, 'hand-drawn': 1, 'tell': 2, 'charming': 1, 'enchanting': 1, 'stories.': 1, \"I'm\": 4, 'terribly': 2, 'disappointed': 1, 'receive': 1, 'many': 8, 'awards': 1, 'accolades,': 1, 'far': 4, 'deserving': 1, 'there.': 2, 'And,': 1, 'FINALLY,': 1, 'that,': 1, \"would've\": 1, 'handled': 2, 'competent': 1, 'Jerry': 1, 'Falwell.': 1, 'high': 1, 'adventure': 1, 'best.': 1, 'helps': 2, 'along': 2, '(maybe': 1, 'idiot-savant': 1, 'sister': 1, 'played': 5, 'better),': 1, 'From': 1, 'Widmark': 1, 'turns': 2, 'unintentionally': 1, 'comical!': 1, 'convincing': 2, 'fact,': 2, 'stinker': 1, 'smells': 1, 'direct-to-video': 1, 'release.': 1, 'Victor': 1, 'McLaglen': 1, 'Brian': 2, 'DonLevy': 1, 'unrecognizable.': 1, 'lead': 3, 'man': 4, 'charisma-free.': 1, 'inspiring': 1, 'hope': 3, 'released': 2, 'again': 5, 'video': 1, 'DVD.': 1, 'shows': 2, 'strong': 3, 'sibling': 1, 'bond': 1, 'other.': 2, 'find': 6, 'them': 7, 'funny.': 1, 'dialogs': 1, 'extremely': 1, 'shallow': 1, 'insincere.': 1, 'point': 2, 'journey,': 1, 'journey': 1, 'touches': 1, 'member': 1, 'family.': 1, 'writing,': 2, 'actors....an': 1, 'ugly': 1, 'crafted': 1, 'Haggis': 1, 'handle': 1, 'bold': 1, 'strokes': 1, 'storytelling....a': 1, 'picture': 2, 'painted': 1, 'crayons.': 1, 'portrayal': 4, 'family': 3, 'share': 2, 'ups': 2, 'down,': 1, 'love': 5, 'likes': 2, 'Definitely': 2, 'worth': 7, 'checking': 1, 'out.': 3, 'DELETE': 1, 'mind!': 1, 'Saw': 1, 'today': 1, 'effort,': 1, 'messages': 1, 'kids.': 1, 'Lovely': 1, 'thriller': 1, 'Hitchcock,': 2, 'lots': 1, 'shenanigans': 1, 'surrounding': 2, 'murdered': 1, 'spy,': 1, 'kidnapped': 1, 'child,': 2, 'nasty': 1, 'church,': 1, 'foreign': 1, 'random': 1, 'taxidermists.': 1, 'Duris': 1, 'wholesome': 2, 'appearance': 1, 'gives': 3, 'performance.': 2, 'About': 2, 'ten': 1, 'having': 4, 'second': 3, 'thoughts.': 1, 'creates': 1, 'universe,': 1, 'fascinating': 1, 'Yeah,': 1, 'sucked.': 1, 'wouldnt': 1, 'free.': 1, 'awesome': 1, 'Ebay.': 1, 'attempts': 2, 'humor': 1, 'pitiful': 1, 'awful': 2, \"dosen't\": 1, 'thinking': 2, 'basically': 1, 'involves': 1, 'Vulcan': 1, 'stealing': 1, 'Enterprise': 1, 'god': 1, '(seriously)': 1, 'care': 3, 'oh': 1, 'mention': 4, 'Uhura': 1, 'does': 7, 'belly': 1, 'dance': 2, 'distract': 1, 'male': 1, 'guards.': 1, 'Full': 1, 'unconvincing': 1, 'cardboard': 2, 'blandly': 1, 'written': 5, 'Edward': 1, 'Chodorov,': 1, 'produced,': 1, 'directed': 1, 'Jean': 1, 'Negulesco': 1, 'whom': 2, 'deal': 1, 'more.': 1, 'Mark': 1, 'Snow': 1, 'possibly': 1, 'score': 3, \"I've\": 5, 'heard.': 1, 'results,': 1, 'shame.': 1, 'Nothing': 3, 'short': 5, 'magnificent': 1, 'photography/cinematography': 1, 'horror.': 1, 'mind-bendingly': 1, 'awful,': 1, 'created.': 2, 'UNfunny': 1, 'pathetic': 3, 'unrealistic': 1, '90': 2, 'utter': 1, 'torture': 1, '70000': 1, 'times!': 1, \"I'd\": 2, 'advise': 1, '1949,': 1, 'Hollywood': 2, 'generally': 1, 'collective': 1, 'heads': 1, 'sand': 1, 'concerning': 1, 'black': 4, 'issues': 2, 'My': 3, '8/10': 1, 'mostly': 2, 'plot.': 2, 'add': 1, 'betty': 1, 'jean': 1, 'smart': 2, '-': 15, 'everyone': 3, 'parts': 2, 'entertaining': 1, 'angles.': 1, 'theater': 2, 'lilt': 1, 'step,': 1, 'heart': 1, 'race.': 1, 'Juano': 1, 'Hernandez': 1, '(an': 1, 'exceptional': 2, 'supporting': 1, 'roles': 3, 'era)': 1, 'proud': 2, 'accused': 2, 'murdering': 1, 'South.': 1, 'interested': 1, 'poetry,': 1, 'theater,': 1, 'politics,': 1, 'Japanese': 1, 'history.': 2, 'baby': 1, 'owls': 1, 'adorable.': 1, 'veteran': 1, 'nostalgia': 1, 'trip.': 1, 'poor': 2, 'remake': 1, '\"My': 1, 'Friends': 1, 'Wedding\".': 1, 'Her': 1, 'role': 3, 'Lot': 1, 'plot:': 1, 'nothing': 4, 'became': 1, 'emperor;': 1, 'where': 6, 'spend': 1, '20': 1, 'years': 1, 'childhood': 1, 'mature': 1, 'age.': 1, 'friends.': 1, 'Filmiing': 1, 'less': 3, 'expansive.': 1, 'year,': 1, 'however,': 1, 'reminded': 1, 'us': 1, 'Huston': 1, 'game': 2, 'evinced': 1, 'faithful': 1, 'adaptation': 1, 'James': 1, \"Joyce's\": 1, 'acclaimed': 1, 'novella': 1, '\"The': 2, 'Dead.': 1, 'By': 1, 'ended,': 1, 'disliked': 1, 'despised': 1, 'Lassie': 1, '\"put': 1, 'sleep\"....': 1, 'FOREVER.': 1, 'Regardless,': 1, 'levels.': 1, 'Instead,': 1, 'bore': 2, 'fest': 1, 'whiny,': 1, 'spoiled': 1, 'brat': 1, 'babysitting.': 1, 'Give': 1, 'look.': 1, 'long': 4, 'length,': 1, 'enjoyed': 6, 'minute': 3, 'Speaking': 1, 'music,': 2, 'unbearably': 1, 'predictably': 2, 'kitchy.': 1, 'Interview': 1, 'Vampire': 1, 'Lestat': 1, '(Stuart': 1, 'Townsend)': 1, \"Cruise's\": 1, 'attempt.': 1, 'quite': 3, 'When': 2, 'song': 3, 'emotions': 1, 'subjects': 1, 'better,': 1, 'Jay': 1, \"Adams'\": 1, 'unfortunate': 1, 'life': 1, 'subject': 1, 'talk,': 1, 'Old': 1, 'Man': 1, 'Neil': 1, 'Young': 1, 'played,': 1, 'evokes': 1, 'emotions.': 1, 'realize': 1, 'until': 1, 'scenes.': 1, 'decidely': 1, 'wooden,': 1, 'period': 1, 'Universal': 1, 'B': 1, 'Director': 1, 'Matthews,': 1, 'wrote/directed': 1, '1995': 1, 'monster': 1, '\"Grim\",': 1, 'clearly': 2, 'pace': 1, 'Constantine': 1, 'everything': 2, 'intensity': 1, 'understanding': 1, 'underlying': 2, 'psychological': 1, 'motivations.': 1, 'few': 3, 'depth,': 1, 'often': 2, 'occasionally': 3, 'touching': 2, 'evaluate': 1, 'lives': 1, 'going.': 1, 'chance--it': 1, 'open': 1, 'race': 1, '50': 1, 'Of': 2, 'course,': 2, 'blah.': 1, 'Then': 3, 'debated': 1, 'whether': 1, 'sack': 1, 'trumpeter': 1, '(who': 1, 'falsely': 1, 'murder)': 1, 'pure': 1, 'horror,': 1, '30': 1, 'footage': 1, 'wasted': 2, 'show': 5, 'mediocre': 2, 'elderly': 1, 'awkwardly': 1, 'babbling': 1, 'overwrought': 1, 'pseudo-Satanic': 1, 'gibberish': 1, 'corny': 1, 'enough': 2, 'teen': 1, 'Goth': 1, 'blush,': 1, 'Olde': 1, 'English,': 1, 'Latin': 1, 'words.': 1, 'Oh': 1, 'yeah,': 1, 'storyline': 1, 'too.': 2, 'Horrible!': 1, 'children': 1, 'screen.': 1, 'Frankly,': 1, 'Cotton': 1, 'club': 1, 'Unfaithful,': 1, 'embarrassing': 1, 'Lane': 1, 'Gere': 1, 'BAD.': 1, 'walked': 2, 'faster.': 1, 'leave': 1, 'wanting': 1, 'under': 3, 'stars.': 2, 'definitely': 4, 'classic,': 1, 'cat': 1, 'n': 1, 'mouse': 1, 'games': 2, 'follow': 1, 'delight': 1, 'longer': 1, 'goes': 1, 'on,': 1, 'surprised': 1, '(especially': 1, 'designed': 1, 'camera)': 1, 'amazing....stylized,': 1, 'beautiful': 3, 'effective.': 1, 'Elias': 1, 'Koteas,Jack': 1, 'Palance': 1, 'Angelina': 1, 'hot': 1, 'naked.Billy': 1, 'appears': 1, 'usual': 1, '+': 1, 'cameo': 1, 'Sven': 1, 'ole': 1, 'Thorsen': 1, 'enjoyable': 2, 'budget.': 1, 'His': 2, 'alongside': 1, 'Olivia': 1, 'De': 1, 'Havilland': 1, 'fantastic!': 1, 'sorry': 1, 'anyone.': 1, 'After': 1, 'wanted': 1, 'learn': 1, 'artist.': 1, 'word': 2, 'loosely)': 1, 'insult': 4, 'movie-going': 1, 'public.': 1, 'Even': 3, 'women': 2, 'finally': 2, 'up,': 1, 'sign': 1, 'improvement;': 1, 'expected': 1, 'happen': 1, 'over,': 1, 'might': 1, 'asleep.': 1, 'Funny,': 1, 'clever,': 1, 'hip': 1, \"Pray's\": 1, 'Hype!': 1, 'dropped': 1, 'ball.': 1, 'None': 1, 'engaging': 2, 'exciting.': 1, 'begin': 1, 'ass': 1, 'ed': 1, 'comments': 1, 'wall': 1, 'uncalled': 1, 'for.': 1, 'annoying.': 2, 'seriously.': 1, 'John': 2, 'Garfield,': 1, 'Ann': 1, 'revere,': 1, 'Lilli': 1, 'Plmer,': 1, 'William': 1, 'Conrad,': 1, 'Canada': 1, 'Lee...and': 1, 'filmed': 1, 'greatest': 2, 'cinematographers': 1, 'grace': 1, 'screen..James': 1, 'Wong': 1, 'Howe.': 1, 'condescends,': 1, 'genuine': 1, 'hearts': 1, 'problems.': 1, 'seeing': 5, '25': 1, 'years,': 1, 'amazed': 1, 'timeless': 1, 'is.': 4, 'Exceptionally': 1, 'bad!': 1, 'hang': 1, 'all,': 2, 'appalling.': 2, 'supposed': 1, 'popcorn': 1, 'comedy,': 2, 'mean': 3, 'completely': 3, 'intelligence,': 1, 'hackneyed': 1, 'borders': 1, 'offensive.': 1, \"Let's\": 1, 'start': 1, 'problems\\x97the': 1, 'professor,': 1, 'very,': 2, 'hopeless': 1, 'overacting': 2, 'Each': 1, 'track': 1, 'commands': 1, 'sentiment,': 1, 'contributing': 1, 'characters.': 1, 'budget': 3, 'evidently': 1, 'limited.': 1, 'fish': 1, 'badly': 1, 'underwater': 1, 'shots': 1, 'repeated': 1, 'thousand': 1, 'garbage.': 1, ';)': 1, 'Recommend': 1, 'confidence!': 1, 'terrible': 3, 'PS': 1, 'central': 2, 'finds': 1, 'room': 1, 'blown': 1, 'believe': 7, 'Pitch': 1, 'Black': 1, 'done': 2, 'do': 10, 'distinction': 1, 'Very': 2, 'speak': 1, 'of.': 1, 'painful!': 1, 'pair': 1, 'fishnet': 1, 'stockings': 1, 'direction': 3, 'editing': 2, 'astonishingly': 1, 'ham': 1, 'fisted.': 1, 'rather': 3, 'extraordinary': 1, 'football': 1, 'perplexing.': 1, 'am': 2, 'fan': 2, '...': 1, 'sucked': 1, 'surely': 1, 'coherent': 1, 'screenwriter': 2, 'Air': 1, 'Force': 1, 'One': 5, 'obliged': 1, 'sum': 1, 'money.': 2, 'reason.': 1, 'paced,': 1, 'understated': 1, 'courtroom': 2, 'documentaries': 2, 'Well...': 1, 'Just': 1, 'stand': 1, 'fear': 2, 'losing': 2, 'I.Q.': 1, '\"oh-so-mature\"': 1, 'neighbour-girl': 1, 'misplace.': 1, 'say': 6, 'spoilers,': 1, 'one,': 1, 'How': 1, 'trash': 2, 'me:': 1, 'characters,': 2, \"etc...it's\": 1, 'ALL': 1, 'fat': 1, 'computer': 1, 'geek': 1, 'unbelievable,': 1, 'bible': 1, 'thumper,': 1, 'bad-ass': 1, 'actors???': 1, 'practically': 1, 'perfect': 5, 'masterpiece': 1, 'sea': 2, '\"masterpieces.': 1, 'audience': 2, 'applauded': 1, 'conclusion': 1, 'Okay,': 1, 'myself': 3, 'fair': 1, 'critic,': 1, 'credit': 1, \"credit's\": 1, 'due--the': 1, 'creature': 1, 'cool.': 1, 'rating:': 1, '3': 2, '10.': 1, 'remember': 2, 'senses': 1, 'assaulted': 1, 'strident': 1, 'cords': 1, 'blare': 1, 'warning,': 1, 'meaning.': 1, 'sure': 1, 'lost': 2, 'flat': 1, 'audience,': 1, 'nearly': 1, 'half': 1, 'thing:': 1, 'tolerate': 1, 'political': 1, 'incorrectness': 1, 'artistic': 1, 'freedom': 1, 'suspension': 1, 'disbelief,': 1, 'Slavic': 1, 'female': 2, 'much.': 1, 'relate': 1, 'them,': 1, 'warmth': 1, 'generates': 1, 'contrast': 1, 'austere': 1, 'backdrop.': 1, 'struggle': 1, 'ceases': 1, 'interest': 2, 'me,': 1, 'simply': 3, 'keeps': 2, 'alert,': 1, 'try': 1, 'attempt': 1, 'decipher': 1, 'meanings.': 1, '10': 5, ')': 4, 'terrific': 4, 'scenery.': 1, \"Estevez's\": 1, 'directorial': 2, 'debut,': 1, 'pacing,': 1, 'development': 1, 'clever': 1, 'Estevez': 1, 'suggest': 1, 'natural': 1, 'eye.': 1, 'Overall': 1, '1-10': 1, 'Yes,': 1, 'Beware:': 1, 'trashy': 1, 'cult': 2, '-period!': 1, 'For': 1, 'timers': 1, 'making,': 1, 'job!!': 1, '20th': 1, 'Century': 1, \"Fox's\": 1, 'ROAD': 1, 'HOUSE': 1, '1948)': 1, 'silly': 1, 'noir': 1, 'implausible': 2, 'unmitigated': 1, 'marbles': 1, 'proceedings': 2, 'unconvincing.': 2, 'America.': 1, 'tremendously': 2, 'played.': 2, 'Kathy': 1, 'Bates': 1, 'desperation': 1, 'escapism;': 1, 'variation': 1, '\"At': 1, 'Play': 1, 'Fields': 1, 'Lord\".': 1, 'turned': 1, 'B-list': 1, 'horror/suspense': 1, 'go.': 1, 'empty,': 1, 'hollow': 1, 'shell': 1, 'An': 2, 'premise,': 1, 'Billy': 1, 'dangerous': 1, 'nut-bag': 1, '(side': 1, 'note:': 1, 'Drago,': 1, 'Stephen': 1, 'McHattie': 1, 'Lance': 1, 'Hendrikson': 1, 'together;': 1, 'talk': 2, 'raging': 1, 'cheekbones!).': 1, 'understand,': 1, 'idiot': 1, 'produce': 1, 'several': 1, 'season.': 1, 'Dustin': 1, \"Hoffman's\": 1, 'ready': 1, 'stay': 2, 'son.': 1, 'sick': 1, 'slackers': 1, 'excuses': 1, 'stupid': 2, 'actions': 1, 'minutes.': 1, '1/10': 1, 'setting': 1, '0/10.': 1, 'sort': 3, 'provoking': 1, 'forces': 2, 'threshold': 1, 'loneliness.': 1, 'shattered': 1, \"'film'\": 1, 'took': 1, 'hours': 1, 'fully': 1, 'recover.': 1, \"film's\": 1, 'natural,': 1, 'edge': 1, 'seat': 1, 'somewhat': 2, 'afraid': 2, 'car': 1, 'night.': 1, 'telephone': 1, 'repair': 1, 'reactions': 2, 'nuts': 1, 'bitchy': 1, 'boss': 1, 'truly': 4, 'genuine.': 1, 'picked': 1, 'speed': 1, 'point.': 1, 'Jimmy': 1, 'Stewart': 1, 'hero': 1, 'rips': 1, 'climax': 1, 'embassy': 1, 'function,': 1, 'brooding': 1, 'menace': 1, \"Hitchcock's\": 1, 'white,': 1, 'low-budget': 1, 'movies,': 2, 'contract': 1, 'player': 1, 'control': 1, 'scripts,': 1, 'television': 1, 'plus': 1, 'could.': 1, 'Overall,': 2, 'delight!': 1, 'classic': 1, 'viewing': 1, 'sharing': 1, 'others.': 1, 'pap': 1, 'screened': 1, 'afternoon': 1, 'punish': 1, 'unemployed': 1, 'jobs.': 1, \"isn't\": 2, 'marred': 1, 'constant': 1, 'studio': 1, 'indoor': 1, 'exteriors.': 1, 'idea': 2, 'volcano': 2, 'Los': 2, 'Angeles?': 1, 'gloriously': 1, 'fun,': 1, 'paced': 1, 'fairly': 1, 'accurate': 1, 'raver.': 1, 'have,': 1, 'recently': 1, 'Fox': 1, 'Movie': 1, 'Channel,': 1, 'disappointed.': 1, 'child': 1, '1973,': 1, 'Stranger\"': 1, 'war': 1, 'love.': 1, 'clear': 1, 'range': 1, 'pull': 1, 'part.': 2, 'rent': 2, 'gave': 2, '10+!': 1, 'continuously': 1, 'Bertolucci,': 1, 'relationships': 2, 'narrative': 1, \"master's\": 1, 'work.': 1, 'prompted': 1, 'documentary': 2, 'me!': 1, 'rough': 1, 'draft': 1, 'shooting': 1, 'began': 2, 'finished': 1, 'completed.': 1, \"one's\": 1, 'intelligence': 1, 'huge': 2, 'bring': 1, 'pillow': 1, 'girlfriend/boyfriend': 1, 'occupied': 1, 'solid': 2, 'revealing.': 1, 'needed': 2, 'word-of-mouth': 1, 'promote,': 1, 'revealing': 1, 'complexity': 1, 'task': 1, 'incredible': 2, 'challenges': 1, 'facing': 1, 'South': 2, 'Africa.': 1, 'redeeming': 1, 'features.': 1, 'presents': 2, 'idyllic': 1, 'yet': 2, 'downs': 1, 'lives.': 1, 'Non-linear': 1, 'narration': 1, 'thus': 1, 'flashbacks': 1, 'articulated': 1, 'rocked': 1, 'world': 1, 'social': 1, 'physical': 1, 'outlets.': 1, 'MANNA': 1, 'FROM': 1, 'HEAVEN': 1, 'unpredictable': 1, 'looking': 1, 'marriage.': 1, 'deserved': 2, 'called': 1, 'lead.': 1, 'scares': 1, 'tension': 2, 'medical': 1, 'terminology': 1, 'used': 4, 'iffy': 1, 'insulin': 1, 'dependant': 1, 'diabetic': 1, 'myself.': 2, 'problems': 1, 'dont': 1, 'start.': 1, 'seemed': 1, 'first.': 1, 'Sundays': 1, 'ago': 1, '(March': 1, '20th,': 1, '2005)': 1, 'enjoy': 2, 'taped': 1, 'soap': 1, 'operas': 1, 'Things': 1, 'happen,': 1, 'personalities': 1, 'change,': 1, 'twists': 1, 'occur': 1, 'reason': 2, 'calls': 1, 'adorable': 1, 'Mickey': 2, 'playing': 3, '\"Turkey': 1, 'Straw\"': 1, 'imaginative': 1, '(if': 1, 'cruel)': 1, 'excellent!Angel': 1, 'Scamp': 2, 'adorable!His': 1, 'yelps': 1, 'hes': 1, 'scared,and': 1, 'funniest': 1, 'when:Scamp': 1, 'caught': 1, 'curtain': 1, 'Angel': 2, 'singing': 1, \"'Ive\": 1, 'Never': 2, 'Had': 1, 'Feeling': 1, \"Before'.I\": 1, 'movie,its': 1, 'coming': 2, 'edition': 1, 'June': 1, '20.The': 1, 'cover': 1, 'scamp': 1, 'underneath': 1, 'lid.': 1, 'Achille': 1, 'Philippa': 1, 'beautifully': 2, 'sing': 1, 'duet': 2, '\"Don': 1, 'Giovanni\"': 1, 'perfectly': 3, 'describes': 1, 'situation': 1, 'layers': 1, 'full': 1, 'dancing': 1, '(hence': 1, 'title!': 1, 'team': 1, 'behind': 1, 'continue': 1, 'own,': 1, 'weird': 1, 'style.': 1, 'youtube.': 1, 'decay,': 1, 'Shakespears': 1, 'lyrics...': 1, 'one.': 1, 'overall,': 1, 'latched': 1, 'endearing': 1, 'become': 3, \"family's\": 1, 'memories.': 1, 'screamy': 1, 'masculine': 1, 'peculiarity': 1, 'Which': 1, 'precisely': 1, 'giving': 1, 'review!': 1, 'fresh,': 1, 'subtle,': 1, 'sublime': 1, 'effect.': 1, 'Technically,': 1, 'camera-work,': 1, 'Riz': 1, 'Ortolani': 1, 'recurring': 1, 'unaccompanied': 1, 'vocal': 1, 'sounds': 1, 'distant': 1, 'hill.': 1, 'Angus': 1, 'Scrimm': 1, 'performance': 3, 'brief': 2, 'memorable': 3, 'gently': 1, 'menacing,': 1, 'violin-playing': 1, 'anatomist': 1, 'Doctor': 1, 'Quinn.': 1, 'achievement': 1, '\"so-bad-it\\'s-good\"': 1, '\"so-bad-it\\'s-memorable\"': 1, 'disappointing.': 1, 'Armand': 1, 'Assante': 1, 'cable': 1, \"company's\": 1, 'summary': 1, 'sounded': 1, 'twice': 1, 'already,': 1, 'astronaut': 1, 'doctor': 1, 'exchange': 1, 'considers': 1, 'Cold': 1, 'War': 1, \"astronaut's\": 1, 'biggest': 1, 'crashed': 1, 'USSR.': 1, 'Predictable,': 1, 'excuse': 1, 'poorly': 1, 'done.': 1, 'awesome!': 1, 'handles': 1, 'tough': 1, 'dignity': 1, 'grace,': 1, 'and,': 1, '(shocking': 1, 'spoiler': 1, 'here!': 1, 'THERE': 1, 'IS': 1, 'PLOT': 1, 'OR': 1, 'STORYLINE!!': 1, 'outside': 1, 'Africa': 1, 'past': 1, 'attempted': 1, 'Truth': 1, 'Reconciliation': 1, 'process.': 1, 'Ireland': 1, 'whatsoever.': 1, 'feel-good': 1, \"that's\": 2, 'came': 1, 'cinema!': 1, 'shameful.': 1, 'frightening': 1, 'least,': 1, 'comprehensible.': 1, 'Generally;': 1, 'lacked': 1, 'imagination.': 2, 'horrendous.': 1, 'Stanwyck': 1, 'Morgan': 1, 'ways,': 1, 'modern': 1, 'equivalent': 1, \"Dickens'\": 1, 'Christmas': 1, 'Carol': 1, 'sensibility.': 1, 'suffered': 1, 'recommend.': 1, '\"explosion\"': 1, 'Gas': 1, 'tanks': 1, 'awful.': 2, 'meaning': 1, 'phrase,': 1, '\"Never': 1, 'history': 1, 'conflict': 1, 'owed': 1, 'few.': 1, 'NOBODY': 1, 'identifies': 1, \"they're\": 1, 'cutouts': 1, 'stereotypes': 1, '(or': 1, 'reverse-stereotypes).': 1, 'different': 1, 'production': 2, 'values': 1, 'faultless': 1, 'photography,': 1, 'underappreciated': 1, 'Keith': 1, 'bully': 1, 'Teddy': 1, 'vivid': 1, 'Special': 1, 'integral': 1, 'element': 2, 'helping': 1, 'cartoon.': 1, 'campy': 1, 'review': 1, 'overdue,': 1, 'since': 2, 'Tale': 1, 'Two': 1, 'Sisters': 1, 'unbearable': 1, 'screen,': 1, 'charisma,': 1, 'comedic': 1, 'timing.': 1, 'Paolo': 1, 'Sorrentino': 1, 'loneliness': 1, 'Tony': 1, 'built': 1, 'unforgettable': 1, 'heard': 1, 'except': 1, 'Cole': 1, 'given': 1, 'Unfortunately,': 2, \"'Cover\": 1, \"Girl'\": 1, 'exploit': 1, 'financial': 1, 'gain.': 1, 'Having': 1, 'humour': 2, 'him': 1, 'day': 1, 'apt.': 1, 'Christmas,': 1, 'was!': 1, 'rare': 1, 'film-maker': 1, 'takes': 1, 'worthy': 1, 'moral': 2, 'fall': 1, 'trap': 1, 'syrupy': 1, 'indulgent.': 1, 'Almost': 2, 'songs': 1, 'Cover': 1, 'Girl': 1, 'old-fashioned': 1, 'tuneful.': 1, 'predictable,': 1, 'flick.': 1, \"Don't\": 2, 'places.': 1, 'Aside': 1, 'lead,': 1, 'loads': 2, 'debits.': 1, 'subtitles........': 1, 'aversion': 1, 'therapy': 1, '10/10': 2, 'tying': 1, 'loose': 1, 'ends.': 1, 'Kris': 1, 'Kristoffersen': 1, 'difference.': 1, 'series.': 1, 'horrible,': 1, 'cause': 1, 'BAD': 1, 'Actors,': 1, 'period.': 1, 'steve': 1, 'martin': 1, 'delivers': 1, 'middle-aged,': 1, 'upper': 1, 'class,': 1, 'uptight': 1, 'guy.': 1, 'forget': 1, 'top,': 1, 'excessively': 1, 'phony': 1, 'contrived': 1, 'painful': 1, 'sit': 1, 'through.': 1, 'attractive': 1, 'eye-pleasing': 1, 'gem.': 1, 'actress,': 1, 'repeating': 1, 'robotic': 1, 'face': 1, 'moves': 1, 'pictures.': 1, 'details': 1, 'dysfunction--he': 1, 'believable.': 1, 'While': 1, 'hear': 1, 'speak,': 1, 'tons': 1, 'film--something': 1, 'granted': 1, 'crowd': 1, 'pleaser': 1, '1928.': 1, 'actress.': 1, 'realized': 1, 'closed': 1, 'brilliance': 1, 'depicts,': 1, 'found': 2, 'nonsense': 1, 'slightest': 1, 'uniqueness': 1, \"bad...well...it's\": 1, 'They': 2, 'exemplars': 1, 'designer.': 1, 'easy': 3, 'love,': 1, 'identify': 1, 'with.': 1, 'scale': 1, 'balanced': 1, 'underacting.': 1, 'popular': 1, 'cinema,': 1, 'house': 1, 'plenty': 1, 'laughs.': 1, 'let': 2, 'girlfriend': 1, 'idea,': 1, 'hated': 1, '\"Tiny': 1, 'Toons\"': 1, 'kept': 1, 'vibe': 1, 'delivered': 1, 'popular,': 1, 'underrated': 1, 'cartoons': 1, 'Lifetime': 1, 'air': 1, 'enough,': 1, 'knows': 1, 'store': 1, 'sells': 1, 'must-have.': 1, 'drama,': 1, 'compelling,': 1, 'indictment': 1, 'American': 1, 'justice': 1, 'system,': 1, 'super': 1, 'depicts': 1, 'vessel': 1, 'taken': 1, 'mighty': 1, 'frost.': 1, 'Omit': 1, 'this.': 2, 'Ursula': 1, \"Burton's\": 1, 'nun': 1, 'making': 2, 'fun': 1, 'nuns': 1, 'church.': 1, 'uneasy': 1, 'was,': 1, 'scared': 1, 'thought-provoking.': 1, 'worse.': 1, 'Ms.': 1, 'disappointment.': 1, 'Later': 1, 'power': 1, 'problem': 1, 'villain': 1, 'low': 2, 'Michael': 1, 'Ironside.': 1, 'Clever': 1, 'crowd-pleaser--this': 1, 'ranks': 1, 'among': 1, \"Mickey's\": 1, '80': 1, 'Both': 2, 'Rickman': 1, 'Stowe': 1, 'hilt': 1, \"childrens'\": 1, 'book': 1, 'who--': 1, 'maybe?--': 1, 'subversive': 1, 'tract.': 1, 'wish': 2, 'enter': 1, 'negative': 1, 'values,': 1, 'admins?': 1, 'No': 1, 'whatsoever!': 1, 'Was': 1, 'Cool.': 1, 'becomes': 1, 'dull,': 1, 'uninteresting': 1, 'mess,': 1, 'forgettable': 1, 'Totally': 1, 'different,': 1, 'understatement': 1, 'see,': 1, 'northern': 1, 'positive': 1, 'community': 1, 'represents.': 1, 'return': 1, 'school,': 1, 'pile': 1, 'round.': 1, 'forgot:': 1, 'Casting': 1, 'Trond': 1, 'Fausa': 1, 'Aurvåg': 1, 'Bothersome': 1, 'Man,': 1, 'doing': 2, 'why.': 1, 'squibs': 1, 'bipolarity': 1, 'ruthless': 2, 'thug': 1, 'next': 1, \"Luv's\": 1, 'diaper': 1, 'commercial)': 1, 'trying': 2, 'was.': 1, 'irritating': 1, 'Excellent': 1, 'earth': 1, 'Irons': 1, 'film?': 1, 'happy,': 1, 'feel': 1, 'ending!': 1, 'BORING!': 1, 'Brilliant!': 1, 'deeply': 1, 'impressed': 1, 'pretentious.': 1, 'Much': 1, 'action,': 1, 'suspense,': 1, 'unneeded': 1, 'controversy.': 1, 'notable': 2, \"Bailey's\": 1, 'crisp': 1, 'colored': 1, 'design': 1, 'costumes': 2, 'Eiko': 1, 'Ishioka': 1, 'went': 1, \"Coppola's\": 1, 'Dracula': 1, 'received': 1, 'Oscar.': 1, 'Otherwise,': 1, 'reviews': 1, 'star': 1, 'frustration': 1, 'retarded': 1, 'girls': 1, 'were.': 1, 'highlights': 1, 'fundamental': 1, 'flaws': 1, 'legal': 1, 'process,': 1, 'discovering': 1, 'guilt': 1, 'innocence,': 1, 'rather,': 1, 'court.': 1, 'captures': 1, 'essence': 1, 'Im': 1, 'RPG': 1, 'too,': 1, 'disgrace': 1, 'self-respecting': 1, 'RPGer': 1, 'slow-motion': 1, 'needlessly': 1, 'repeats': 1, 'itself': 1, 'backed': 1, 'here),': 1, 'continuity,': 1, 'whatsoever,': 1, 'vehicles': 1, 'Corn': 1, 'Flakes': 1, 'box': 1, 'style': 1, 'bordered': 1, 'stupidity.': 1, 'stunning': 1, 'deserves': 1, 'kudos': 1, 'taking': 1, 'stand,': 1, 'lesser-known': 1, 'super-intelligent': 1, 'racism.': 1, 'offers': 1, 'delights': 1, 'surprises.': 1, 'Seriously,': 1, 'wasting': 1, 'your,': 1, \"kid's\": 1, 'includes': 1, 'Shatner': 1, 'Nimoy': 1, 'washed': 1, 'old': 1, 'life,': 1, 'tacky': 1, 'Spock': 1, 'rescue': 1, 'Kirk': 1, 'jet': 1, 'pack': 1, 'falls': 1, 'down': 1, 'mountain.': 1, 'Brilliance': 1, 'indeed.': 1, 'Why': 1, 'made?': 1, 'General': 1, \"Loewenhielm's\": 1, 'partaking': 1, 'Cailles': 1, 'en': 1, 'Sarcophage': 1, 'small': 1, 'sample': 1, 'savor.': 1, 'unrecommended.': 1, '(Jason': 1, 'Connery)': 1, 'moved': 1, 'tears': 1, 'final': 1, 'monolog': 1, '(out': 1, 'candle,': 1, 'out)He': 1, 'sphere': 1, 'decay': 1, 'face,': 1, 'interesting.': 1, 'Utterly': 1, 'merit': 1, 'level,': 1, 'akin': 1, 'torture.': 2, 'conclusion,': 1, 'Angeles': 1, 'nonsense.': 1, 'Plus,': 2, 'well-paced': 1, 'suited': 1, 'relatively': 1, 'run': 1, 'Only': 1, 'buildings': 1, 'used,': 1, 'couple': 1, 'locations': 1, 'MAYBE,': 1, 'hummh!': 1, 'situations': 1, '\"acting': 1, 'coach\"': 1, 'fascinating.': 1, 'sequel': 1, 'this!': 1, 'cannot': 1, 'agreed': 1, '\"film\".': 1, 'scared,': 1, 'horrified,': 1, 'sympathetic': 1, 'towards': 1, 'characters;': 1, 'blew.': 1, 'below': 1, 'average': 2, 'rent.': 1, 'She': 1, 'lovely': 1, 'usual,': 1, 'cutie!': 1, \"movie's\": 1, 'modest': 1, 'running': 2, 'time,': 1, 'job!': 1, 'flawed': 1, 'These': 1, 'themes': 1, 'ineptly,': 1, 'stereotypically': 1, 'depth': 1, 'unique': 1, 'though.': 1, \"'Titta\": 1, 'Di': 1, \"Girolamo'\": 1, 'vision': 1, 'disappointing': 1, 'aspects': 1, 'lack': 1, 'gore.': 1, 'great--especially': 1, 'arts.': 1, 'NOTHING': 1, 'Is': 1, 'possible': 1, 'this?': 1, 'Wow,': 1, 'Being': 1, 'proudly': 1, 'classical': 1, 'WB': 1, 'cartoons.': 1, 'boring,pointless': 1, 'twist': 1, 'ending.': 1, 'solid.': 1, 'Conclusion': 1, 'mature,': 1, 'suggests': 1, 'brings': 1, 'dramatic': 2, 'focus': 2, 'tensions': 1, 'served': 1, '(apart': 1, 'odd': 2, 'inappropriate': 1, 'smiling': 1, 'Keira': 1, 'Knightley': 1, 'prone': 1, 'to,': 1, 'it).': 1, 'Punishment': 1, 'Park': 1, 'inexperience': 1, 'meant': 1, 'passed': 1, 'Too': 1, 'politically': 1, 'correct.': 1, 'European,': 1, 'throwback': 1, 'student': 1, \"1980's\": 1, 'experiences': 1, 'living': 1, 'abroad': 1, 'interacting': 1, 'nationalities,': 1, 'circumstances': 1, 'slightly': 1, 'different.': 1, 'Bela': 1, 'Lugosi': 1, 'extraneous,': 1, 'intoning': 1, 'lines.': 1, 'Wind': 1, 'Lion': 1, 'superbly': 1, 'acted.': 1, 'unpleasant.': 1, 'VERY': 1, 'funny!': 1, 'scenery': 1, 'daughters': 1, 'paint': 1, 'photograph': 1, 'basic': 1, 'premise': 1, 'sidelined': 1, 'inexplicable': 1, 'crew.': 1, 'particular': 1, 'delivering': 1, 'convincing,': 1, 'sincere': 1, \"He's\": 1, 'national': 1, 'treasure.': 1, 'person,': 1, 'see.': 1, 'Gerardo': 1, 'head.': 1, 'well-balanced': 1, 'thoroughly': 1, 'slow.': 1, 'Bad': 1, 'acting.': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rfjGdYSPMfI"
      },
      "source": [
        "#cleandata\n",
        "#reomving less frequent words from dataset\n",
        "repeating_words = []\n",
        "for i in words_count.keys():\n",
        "    if (words_count[i]<5):\n",
        "          repeating_words.append(i)\n",
        "for i in repeating_words:\n",
        "    del words_count[i]\n",
        "len(words_count)\n",
        "def removing_less_occurring_words(imdb_data,words_count):\n",
        "    for i, review in enumerate(imdb_data):\n",
        "        clean = []\n",
        "        for word in review.split():\n",
        "            if word in words_count.keys():\n",
        "                clean.append(word)\n",
        "        clean = ' '.join(clean)\n",
        "        imdb_data[i] = clean\n",
        "    return imdb_data"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4cGyZDnPOSN",
        "outputId": "1ca756be-86db-4137-c946-12b7f7c9f0d1"
      },
      "source": [
        "#after removing less occurring data from vocab_list and so from X_train\n",
        "X_train = removing_less_occurring_words(X_train,words_count)\n",
        "print(\"Total unique words in the given dataset after removing less occurring words: \",len(X_train))\n",
        "print('')\n",
        "#print(\"Length of words dictionary after removing less occurred data: \",len(words_count))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unique words in the given dataset after removing less occurring words:  486\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn__IXEnPXvL",
        "outputId": "a666369a-60c7-4c8b-a59f-3ab2a656266a"
      },
      "source": [
        "#my words dictionary after removing less occurring words\n",
        "print(words_count)\n"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'has': 25, 'made': 12, 'a': 233, 'film': 58, 'that': 87, 'is': 182, 'both': 7, '&': 7, 'The': 107, 'of': 199, 'the': 366, 'movie': 70, 'If': 7, \"it's\": 17, 'about': 25, 'it': 84, 'I': 142, 'because': 12, 'All': 6, 'actors': 7, 'give': 5, 'wonderful': 9, 'as': 52, 'who': 23, 'from': 24, 'in': 116, 'through': 5, 'she': 5, 'part': 6, 'to': 128, 'But': 8, 'if': 16, 'you': 31, 'liked': 6, 'movies': 12, 'like': 25, 'better': 8, 'their': 10, 'think': 5, 'thought': 6, 'this': 106, 'will': 14, 'watch': 6, 'This': 44, 'and': 235, 'between': 7, 'we': 6, 'saw': 7, 'with': 50, 'off': 5, 'was': 104, 'how': 15, 'little': 12, 'there': 14, 'on': 35, 'two': 12, 'Not': 5, 'for': 52, \"don't\": 10, 'anything': 5, 'or': 25, 'even': 17, 'its': 16, 'were': 17, 'just': 35, 'recommend': 8, 'it.': 20, 'one': 26, 'any': 15, 'real': 8, 'There': 6, 'film,': 6, 'understand': 6, 'he': 18, 'would': 8, 'his': 21, 'out': 19, 'really': 25, 'loved': 5, 'story': 13, 'line': 5, 'anyone': 7, 'an': 26, 'watching': 11, 'her': 11, 'It': 29, 'great': 19, \"didn't\": 7, 'be': 22, 'get': 8, 'are': 42, 'so': 27, 'they': 12, 'look': 8, 'things': 5, 'into': 11, 'absolutely': 6, 'watch.': 5, 'films': 9, 'very': 25, 'no': 16, 'scenes': 9, 'minutes': 5, 'also': 13, 'not': 35, 'bad': 26, 'well.': 6, 'such': 8, 'is,': 5, 'ending': 5, 'but': 38, 'good': 23, 'makes': 6, 'only': 14, 'ever': 15, 'could': 11, 'have': 24, 'been': 9, 'more': 24, 'than': 12, 'funny': 6, 'i': 7, 'when': 18, 'time': 14, 'see': 10, 'your': 11, 'acting': 22, 'special': 7, \"can't\": 7, '1': 17, 'me': 8, 'best': 11, 'character': 9, 'acting,': 6, '0': 38, \"It's\": 19, 'movie.': 15, 'every': 8, 'those': 6, 'dialogue': 5, 'Everything': 5, 'writing': 6, 'directing': 6, 'make': 13, 'go': 5, 'after': 9, 'waste': 6, 'time.': 9, 'In': 5, 'it,': 6, 'pretty': 6, 'scene': 8, 'at': 33, 'A': 7, 'totally': 9, 'subtle': 5, 'by': 28, 'years.': 5, 'characters': 19, 'all': 27, 'probably': 5, 'some': 12, 'being': 7, 'script': 10, 'too': 5, 'What': 5, 'kind': 5, 'plot': 13, 'You': 6, 'film.': 11, 'throughout': 6, 'music': 8, 'seen': 6, 'my': 12, 'should': 5, 'know': 11, 'what': 11, 'most': 11, 'way': 6, 'interesting': 6, 'watched': 5, 'can': 9, 'people': 7, 'bad.': 7, 'cast': 7, 'well': 13, \"doesn't\": 10, 'work': 5, 'movie,': 7, 'had': 15, 'much': 5, 'over': 9, 'each': 5, 'joy': 5, 'big': 5, 'other': 8, 'And': 6, 'actually': 6, 'which': 10, 'white': 6, 'up': 9, 'still': 6, 'though': 5, 'did': 6, 'excellent': 6, 'end': 5, 'way.': 6, 'many': 8, 'played': 5, 'again': 5, 'find': 6, 'them': 7, 'love': 5, 'worth': 7, 'does': 7, 'written': 5, \"I've\": 5, 'short': 5, '-': 15, 'where': 6, 'enjoyed': 6, 'show': 5, 'seeing': 5, 'believe': 7, 'do': 10, 'One': 5, 'say': 6, 'perfect': 5, '10': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cojTbr2_PZvo",
        "outputId": "9ed17ac3-76a6-403b-d991-1af0ca666942"
      },
      "source": [
        "review_0_train = train_set[Y_train == 0]\n",
        "print(f'Total 0 (negative) review in train dataset : {len(review_0_train)}')\n",
        "\n",
        "review_1_train = train_set[Y_train == 1]\n",
        "print(f'Total 1 (positive) review in train dataset : {len(review_1_train)}')"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 0 (negative) review in train dataset : 230\n",
            "Total 1 (positive) review in train dataset : 256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoqVkvl7WSCY"
      },
      "source": [
        "c.) Find basic probability gor positive and negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7mPJ-N_PcN5",
        "outputId": "1f0d442b-3fbe-4a6b-ec43-a93c96ba3219"
      },
      "source": [
        "#count basic probability for positive and negative reviews\n",
        "def calculate_prior_class_prob(Y_train):\n",
        "  prior_class_prob = {}\n",
        "  for c in np.unique(Y_train):\n",
        "    count = sum(Y_train == c)\n",
        "    prior_class_prob[c] = count / Y_train.size\n",
        "  return prior_class_prob\n",
        "\n",
        "prior_class_prob = calculate_prior_class_prob(Y_train)\n",
        "print(f'prior probability of class 0 (negative) : {prior_class_prob[0]}')\n",
        "print(f'prior probability of class 1 (positive) : {prior_class_prob[1]}')"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prior probability of class 0 (negative) : 0.4732510288065844\n",
            "prior probability of class 1 (positive) : 0.5267489711934157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGfX6pQDPhZ_"
      },
      "source": [
        "#here we are making dictionary containing word and it's occurrance in data\n",
        "def total_words_in_data(imdb_data, words_count):\n",
        "    new_dict = {}\n",
        "    for word in words_count.keys():\n",
        "        count = 0\n",
        "        for review in imdb_data:\n",
        "            if word in review:\n",
        "                count = count + 1\n",
        "        new_dict[word] = count\n",
        "    return new_dict"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx3SNh1ZPmMt",
        "outputId": "15ef51e1-3d51-49c9-b302-3482569c74dc"
      },
      "source": [
        "words_occ = total_words_in_data(X_train,words_count)\n",
        "print(\"Number of word the in the data : \",words_occ['the'])"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of word the in the data :  238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_KZZy_MWfrO"
      },
      "source": [
        "**-->Probability of the occurrence**</br>\n",
        "P[“the”] = num of documents containing ‘the’ / num of all documents\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYmp7bbCPoBk"
      },
      "source": [
        "#probability of given word in dataset\n",
        "def prob_calc_of_word_in_data(imdb_data, word):\n",
        "    count = 0\n",
        "    if word not in words_occ.keys():\n",
        "        count = 0\n",
        "    else:\n",
        "        count = words_occ[word]\n",
        "    return count/len(imdb_data)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H83gIHF3Pr1p",
        "outputId": "3d11de2b-8213-41a4-c499-a53b159e8bc0"
      },
      "source": [
        "prob_word_in_data = prob_calc_of_word_in_data(X_train, 'the')\n",
        "print(\"Probability of word in whole document: p[the] %: \",prob_word_in_data*100)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probability of word in whole document: p[the] %:  48.971193415637856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZmQ2jSwWreH"
      },
      "source": [
        "**-->Conditional probability based on the sentiment</br>**\n",
        "P[“the” | Positive]  = # of positive documents containing “the”  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVesP5YDPvdT"
      },
      "source": [
        "def positive_words_count(imdb_data, label, words_count):\n",
        "    positive_words = {}\n",
        "    for word in words_count.keys():\n",
        "        pos_count = 0\n",
        "        for index, review in enumerate(imdb_data):\n",
        "            if word in review.split() and label[index]==1:\n",
        "                pos_count = pos_count + 1\n",
        "        positive_words[word] = pos_count\n",
        "    return positive_words\n",
        "\n",
        "def negative_words_count(imdb_data, label, words_count):\n",
        "    negative_words = {}\n",
        "    for word in words_count.keys():\n",
        "        neg_count = 0\n",
        "        for index, review in enumerate(imdb_data):\n",
        "            if word in review.split() and label[index]==0:\n",
        "                neg_count = neg_count + 1\n",
        "        negative_words[word] = neg_count\n",
        "    return negative_words\n",
        "positive_words = positive_words_count(X_train, Y_train, words_count)\n",
        "negative_words = negative_words_count(X_train, Y_train, words_count)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReAsLlyJP4KB",
        "outputId": "0bad8057-65f4-4b66-a9b7-86a30e2a7af4"
      },
      "source": [
        "#in how many positive documents word \"the\" comes\n",
        "positive_words['the']"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "126"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQljM9y3P54T",
        "outputId": "fd645722-57cc-4800-d8a0-46a466e9f609"
      },
      "source": [
        "#in how many negative documents word \"the\" comes\n",
        "negative_words['the']"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHyASy4MP7UN"
      },
      "source": [
        "def positive_doc_count(imdb_data):\n",
        "    positive_doc = 0\n",
        "    for i in range(len(imdb_data)):\n",
        "        if (imdb_data[i]==1):\n",
        "            positive_doc = positive_doc + 1\n",
        "    return positive_doc\n",
        "def negative_doc_count(imdb_data):\n",
        "    negative_doc = 0\n",
        "    for i in range(len(imdb_data)):\n",
        "        if (imdb_data[i]==0):\n",
        "            negative_doc = negative_doc + 1\n",
        "    return negative_doc\n",
        "def pos_neg_doc_count(imdb_data, attribute):\n",
        "    if attribute == \"positive\":\n",
        "        cnt = positive_doc_count(imdb_data)\n",
        "    else:\n",
        "        cnt = negative_doc_count(imdb_data)\n",
        "    return cnt\n",
        "positive_doc = pos_neg_doc_count(Y_train,attribute = \"positive\")\n",
        "negative_doc = pos_neg_doc_count(Y_train,attribute = \"negative\")"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMdc2PwLQHVX",
        "outputId": "90e7c2fe-1df1-46c1-c847-50d5b1c9641b"
      },
      "source": [
        "#number of positive documents\n",
        "print(positive_doc)\n",
        "print(negative_doc)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256\n",
            "230\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbPw0U7HQPMj"
      },
      "source": [
        "#probability of given word in positive or negative document\n",
        "def num_of_word_in_posneg(word,words_count, attribute):\n",
        "    count = 0\n",
        "    if attribute ==\"positive\":\n",
        "        if word in positive_words.keys():\n",
        "            count = positive_words[word]\n",
        "        else:\n",
        "            count = 0\n",
        "            \n",
        "    elif attribute==\"negative\":\n",
        "        if word in negative_words.keys():\n",
        "            count = negative_words[word]\n",
        "        else:\n",
        "            count = 0\n",
        "    return count"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btZfMXQlQSEI",
        "outputId": "35b89300-dcd2-4bd6-fbf8-341ead6e77eb"
      },
      "source": [
        "numerator = num_of_word_in_posneg('the',words_count, attribute = \"positive\")\n",
        "p = numerator/positive_doc\n",
        "print(\"p[the|positive]: \"+str(p*100)+\" %\")"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p[the|positive]: 49.21875 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8u0ujM2W3G3",
        "outputId": "e789ef94-8b0a-4ae3-c949-9d3fe11e8710"
      },
      "source": [
        "numerator = num_of_word_in_posneg('the',words_count, attribute = \"negative\")\n",
        "p = numerator/positive_doc\n",
        "print(\"p[the|negative]: \"+str(p*100)+\" %\")"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p[the|negative]: 35.9375 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txMaBWo6QTqe",
        "outputId": "59e844ac-7545-4d82-fbda-672455ddf532"
      },
      "source": [
        "#probability for p[positive|the] without NAIVE BAYES\n",
        "prob = (p*(positive_doc/len(X_train)))/prob_word_in_data\n",
        "print(\"Probability of given word in data\",prob*100)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probability of given word in data 38.655462184873954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R02tkiO2XCSN"
      },
      "source": [
        "**D) Calculate accuracy using dev dataset **\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwch3wz1QVMt"
      },
      "source": [
        "def NaiveBayes(imdb_data, label, word,words_count, attribute):\n",
        "    numerator = num_of_word_in_posneg(word, words_count,attribute)\n",
        "    denominator = prob_calc_of_word_in_data(imdb_data, word)\n",
        "    posnegdoc = pos_neg_doc_count(label,attribute)\n",
        "    if denominator == 0:\n",
        "        denominator = 0.1\n",
        "    else:\n",
        "        denominator = denominator\n",
        "    result = (numerator/posnegdoc)*(posnegdoc/len(imdb_data))/denominator\n",
        "    return result"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeyQliKeQYQv"
      },
      "source": [
        "def NaiveBayes_for_data(imdb_data,label,words_count,data1):\n",
        "    positive_pred = 1\n",
        "    negative_pred = 1\n",
        "    y_pred = []\n",
        "    for index,review in enumerate(data1):\n",
        "        for word in review.split(\" \"):\n",
        "            a = NaiveBayes(imdb_data, label, word,words_count, attribute = \"negative\")\n",
        "            if a == 0:\n",
        "                a = 0.1\n",
        "            else:\n",
        "                a = a\n",
        "            negative_pred = negative_pred * a\n",
        "            #print(\"n\",negative_pred)\n",
        "            b = NaiveBayes(imdb_data, label, word,words_count, attribute = \"positive\")\n",
        "            if b == 0:\n",
        "                b = 0.1\n",
        "            else:\n",
        "                b = b\n",
        "            positive_pred = positive_pred * b\n",
        "            #print(\"p\",positive_pred)\n",
        "        if positive_pred > negative_pred:\n",
        "            y_pred.append(1)\n",
        "        else:\n",
        "            y_pred.append(0)\n",
        "    return y_pred"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwocyY-qQq9h"
      },
      "source": [
        "y_pred = NaiveBayes_for_data(X_train,Y_train,words_count,X_development)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIRllDdOQuoa"
      },
      "source": [
        "def accuracy(label, prediction):\n",
        "    pred = 0\n",
        "    for i in range(len(label)):\n",
        "        if(label[i]==prediction[i]):\n",
        "            pred = pred + 1\n",
        "        acc = float(pred/len(label))\n",
        "    return acc"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAAsh88QXWcN"
      },
      "source": [
        " **E)Do following experiments\n",
        "Compare the effect of Smoothing**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgQw_J7uQwHb",
        "outputId": "66516289-e52b-4894-ca1a-d6ac14a4698c"
      },
      "source": [
        "#Accuracy without smoothing\n",
        "Accuracy = accuracy(Y_development,y_pred)\n",
        "print(\"Accuracy without smoothing the data:  \"+str(Accuracy*100)+\" %\")"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy without smoothing the data:  47.70992366412214 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4erHVOKlQxue"
      },
      "source": [
        "#smoothing the data\n",
        "def NaiveBayesSmooth(imdb_data, label, word,words_count, attribute):\n",
        "    numerator = num_of_word_in_posneg(word, words_count, attribute)\n",
        "    denominator = prob_calc_of_word_in_data(imdb_data, word)\n",
        "    posnegdoc = pos_neg_doc_count(label,attribute)\n",
        "    if denominator == 0:\n",
        "        denominator = 0.1\n",
        "    else:\n",
        "        denominator = denominator\n",
        "    result = (((numerator/posnegdoc)*(posnegdoc/len(imdb_data)))+1)/(denominator+2)\n",
        "    return result\n",
        "def NaiveBayes_for_Smoothdata(imdb_data,label,words_count,data1):\n",
        "    positive_pred = 1\n",
        "    negative_pred = 1\n",
        "    y_pred = []\n",
        "    for index,review in enumerate(data1):\n",
        "        for word in review.split(\" \"):\n",
        "            a = NaiveBayesSmooth(imdb_data, label, word,words_count, attribute = \"negative\")\n",
        "            if a == 0:\n",
        "                a = 0.1\n",
        "            else:\n",
        "                a = a\n",
        "            negative_pred = negative_pred * a\n",
        "            #print(\"n\",negative_pred)\n",
        "            b = NaiveBayesSmooth(imdb_data, label, word,words_count, attribute = \"positive\")\n",
        "            if b == 0:\n",
        "                b = 0.1\n",
        "            else:\n",
        "                b = b\n",
        "            positive_pred = positive_pred * b\n",
        "            #print(\"p\",positive_pred)\n",
        "        if positive_pred > negative_pred:\n",
        "            y_pred.append(1)\n",
        "        else:\n",
        "            y_pred.append(0)\n",
        "    return y_pred"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lifa3beCQ3Y2"
      },
      "source": [
        "#predicted values for given data \n",
        "y_pred = NaiveBayes_for_Smoothdata(X_train,Y_train,words_count,X_development)"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu_APeoLQ5C8",
        "outputId": "7500fa66-9579-40c0-9260-ff702551f12b"
      },
      "source": [
        "#accuracy after smoothing the data\n",
        "Accuracy = accuracy(Y_development,y_pred)\n",
        "print(\"Accuracy after smoothing the data:  \"+str(Accuracy*100)+\" %\")"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy after smoothing the data:  50.76335877862596 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t_gJZqdXoFr"
      },
      "source": [
        "**-->Derive Top 10 words that predicts positive and negative class\n",
        "P[Positive| word]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3OCmVqZQ6VH"
      },
      "source": [
        "import operator,itertools\n",
        "top_positive={}\n",
        "for word in words_count.keys():\n",
        "    acc = NaiveBayes(X_train, Y_train, word,words_count, attribute=\"positive\")\n",
        "    top_positive[word] = acc\n",
        "top_reversed = dict(sorted(top_positive.items(),key=operator.itemgetter(1),reverse=True))\n",
        "top_10_positive = dict(itertools.islice(top_reversed.items(), 10))"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZm1wm7RRID3",
        "outputId": "7b73da1e-a272-4996-943c-3d9eb6913f5b"
      },
      "source": [
        "#top10 positive \n",
        "print(\"Top 10 words that predict positive class\\n\",top_10_positive.keys())"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 words that predict positive class\n",
            " dict_keys(['wonderful', 'liked', 'think', 'loved', 'watch.', 'well.', 'makes', 'funny', 'years.', 'interesting'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWQwdDSNRJ-D"
      },
      "source": [
        "top_negative={}\n",
        "for word in words_count.keys():\n",
        "    acc = NaiveBayes(X_train, Y_train, word,words_count, attribute=\"negative\")\n",
        "    top_negative[word] = acc\n",
        "top_reversed = dict(sorted(top_positive.items(),key=operator.itemgetter(1),reverse=False))\n",
        "top_10_negative = dict(itertools.islice(top_reversed.items(), 10))"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IusrQ7oFRLiO"
      },
      "source": [
        "top_negative={}\n",
        "for word in words_count.keys():\n",
        "    acc = NaiveBayes(X_train, Y_train, word,words_count, attribute=\"negative\")\n",
        "    top_negative[word] = acc\n",
        "top_reversed = dict(sorted(top_positive.items(),key=operator.itemgetter(1),reverse=False))\n",
        "top_10_negative = dict(itertools.islice(top_reversed.items(), 10))"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V_qEgFVYJLd"
      },
      "source": [
        "**F)Using the test dataset\n",
        "Use the optimal hyperparameters you found in the step e, and use it to calculate the final accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C79Ht5CERM9T",
        "outputId": "a982ace8-5148-41a3-9e92-4f2c73fc9036"
      },
      "source": [
        "shuffle = imdb_data.sample(frac=1).to_numpy()\n",
        "#shuffling data using sample method to get random values in train and development set each time \n",
        "size = int(0.35*len(imdb_data))\n",
        "#i have taken 35% of data as testing.\n",
        "test_set = shuffle[:size]\n",
        "\n",
        "print(\"Size of test set: \",len(test_set))\n",
        "print(\"Shape of test set:\",{test_set.shape})\n",
        "\n"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of test set:  261\n",
            "Shape of test set: {(261, 2)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T-3G_gkRPax"
      },
      "source": [
        "X_test = test_set[:,0] #reviews in X_train\n",
        "Y_test = test_set[:,-1]"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlUcdtUORWdZ"
      },
      "source": [
        "y_pred = NaiveBayes_for_data(X_train,Y_train,words_count,X_test)"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoIdNhk9RYH1",
        "outputId": "3668dd23-d704-41ab-9165-1a05700c98f0"
      },
      "source": [
        "#accuracy without smoothing the test data\n",
        "Accuracy = accuracy(Y_test,y_pred)\n",
        "print(\"Accuracy without smoothing the TEST data:  \"+str(Accuracy*100)+\" %\")"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy without smoothing the TEST data:  51.34099616858238 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crV1IsV4RaBO"
      },
      "source": [
        "y_pred = NaiveBayes_for_Smoothdata(X_train,Y_train,words_count,X_test)"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPbqY6teRbqZ",
        "outputId": "7081809c-81b2-4cef-8b7b-79a2545aa498"
      },
      "source": [
        "#accuracy after smoothing the test data\n",
        "Accuracy = accuracy(Y_test,y_pred)\n",
        "print(\"Accuracy after smoothing the TEST data:  \"+str(Accuracy*100)+\" %\")"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy after smoothing the TEST data:  53.63984674329502 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq8DNuo4RnRP"
      },
      "source": [
        ""
      ],
      "execution_count": 156,
      "outputs": []
    }
  ]
}